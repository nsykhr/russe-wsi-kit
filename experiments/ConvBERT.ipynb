{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will try clustering contextual word representations from DeepPavlov's conversational RuBERT for the task of Word Sense Induction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "from typing import List, Tuple, Dict, Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "from sklearn.cluster import AffinityPropagation, AgglomerativeClustering, Birch\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_tokenizer = RegexpTokenizer(r'[А-Яа-яЁё]+|[A-za-z]+|\\w+|[«»\\'\",.:;!?\\(\\)-–—]|[^\\w\\s]+')\n",
    "word_tokenize = re_tokenizer.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>word</th>\n",
       "      <th>gold_sense_id</th>\n",
       "      <th>predict_sense_id</th>\n",
       "      <th>positions</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(18, 22)]</td>\n",
       "      <td>Отвергнуть щедрый дар</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(21, 28)]</td>\n",
       "      <td>покупать преданность дарами и наградами</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(19, 23)]</td>\n",
       "      <td>Вот яд – последний дар моей Изоры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(81, 87)]</td>\n",
       "      <td>Основная функция корильных песен – повеселить ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>дар</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(151, 157)]</td>\n",
       "      <td>Но недели две спустя (Алевтина его когда-то об...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2068</td>\n",
       "      <td>2069</td>\n",
       "      <td>зонт</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(85, 91)]</td>\n",
       "      <td>Такая погода легко переживается весной, а вот ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2069</td>\n",
       "      <td>2070</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(8, 13)]</td>\n",
       "      <td>Пляжный зонт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>2071</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(18, 25)]</td>\n",
       "      <td>сидеть в кафе под зонтом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2071</td>\n",
       "      <td>2072</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(21, 29)]</td>\n",
       "      <td>Cтолики под широкими зонтами, несколько привин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2072</td>\n",
       "      <td>2073</td>\n",
       "      <td>зонт</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(62, 70)]</td>\n",
       "      <td>Я выскочила из Исторического музея в летнее ка...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2040 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      context_id  word gold_sense_id  predict_sense_id     positions  \\\n",
       "0              1   дар             1               NaN    [(18, 22)]   \n",
       "1              2   дар             1               NaN    [(21, 28)]   \n",
       "2              3   дар             1               NaN    [(19, 23)]   \n",
       "3              4   дар             1               NaN    [(81, 87)]   \n",
       "4              5   дар             1               NaN  [(151, 157)]   \n",
       "...          ...   ...           ...               ...           ...   \n",
       "2068        2069  зонт             1               NaN    [(85, 91)]   \n",
       "2069        2070  зонт             2               NaN     [(8, 13)]   \n",
       "2070        2071  зонт             2               NaN    [(18, 25)]   \n",
       "2071        2072  зонт             2               NaN    [(21, 29)]   \n",
       "2072        2073  зонт             2               NaN    [(62, 70)]   \n",
       "\n",
       "                                                context  \n",
       "0                                 Отвергнуть щедрый дар  \n",
       "1               покупать преданность дарами и наградами  \n",
       "2                     Вот яд – последний дар моей Изоры  \n",
       "3     Основная функция корильных песен – повеселить ...  \n",
       "4     Но недели две спустя (Алевтина его когда-то об...  \n",
       "...                                                 ...  \n",
       "2068  Такая погода легко переживается весной, а вот ...  \n",
       "2069                                       Пляжный зонт  \n",
       "2070                           сидеть в кафе под зонтом  \n",
       "2071  Cтолики под широкими зонтами, несколько привин...  \n",
       "2072  Я выскочила из Исторического музея в летнее ка...  \n",
       "\n",
       "[2040 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/nsykhr/russe-wsi-kit/master/data/main/active-dict/train.csv', sep='\\t')\n",
    "data.dropna(subset=['positions'], inplace=True) # let's drop the rows where the relevant token is not present in the context\n",
    "data.positions = data.positions.apply(lambda x: [tuple(map(int, pos.split('-'))) for pos in x.split(',')])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_words = {key: [] for key in data.word.unique()}\n",
    "for _, row in data.iterrows():\n",
    "    data_by_words[row.word].append((row.context, row.positions, row.gold_sense_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvBERT + Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try clustering contextual word embeddings. By design, they are meant to encode tokens as a weighted sum of embeddings of all the tokens in a sequence. Therefore, clustering BERT embeddings is similar to the embedding clustering approaches described in, for example, https://arxiv.org/abs/1805.02258.\n",
    "\n",
    "We do not know the number of clusters in advance, but one can tune the clustering hyperparameters on the training data. Besides the clustering hyperparameters and the clustering algorithm itself, it is a good idea to try dimensionality reduction (it may help alleviate the dimensionality curse).\n",
    "\n",
    "To choose the number of clusters for Agglomerative Clustering, I will be using the idea introduced in https://www.aclweb.org/anthology/S19-2004.pdf (iterating over all sensible values and choosing the one that yields the best silhouette score).\n",
    "\n",
    "I chose to use the conversational version of DeepPavlov's RuBERT because it yields significantly better results, according to my preliminary experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUBERT_PATH = '../../RuBERT/ru_conversational_cased_L-12_H-768_A-12_pt'\n",
    "USE_GPU = False\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(RUBERT_PATH, do_lower_case=False)\n",
    "model = BertModel.from_pretrained(RUBERT_PATH)\n",
    "if USE_GPU:\n",
    "    model = model.cuda()\n",
    "model.eval()\n",
    "device = torch.device('cuda:0' if USE_GPU else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLS_ID = tokenizer.vocab[tokenizer.cls_token]\n",
    "SEP_ID = tokenizer.vocab[tokenizer.sep_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contextual_embeddings(sentence: str, char_positions: List[Tuple[int, int]], return_mean: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    We need to carefully find the tokens corresponding to the provided positions\n",
    "    and return either the mean of their first wordpieces' contextual embeddings\n",
    "    or the mean of all of their wordpieces' contextual embeddings.\n",
    "    \n",
    "    1. Tokenize the text with conventional means and write down the relevant tokens' indices.\n",
    "    2. Tokenize the tokens one by one using BERT wordpiece tokenizer and write down the relevant wordpieces' indices.\n",
    "    3. Calculate the wordpieces' contextual embeddings by running BERT.\n",
    "    4. Return the mean of the relevant wordpieces' embeddings.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We set acc_len to 1 in order to account for the [CLS] token we will prepend to the sequence later.\n",
    "    input_indices, wordpiece_positions, acc_len = [], [], 1\n",
    "    relevant_tokens = {sentence[pos[0]:pos[1]-1] for pos in char_positions}\n",
    "    \n",
    "    for i, token in enumerate(word_tokenize(sentence)):\n",
    "        indices = tokenizer.encode(token, add_special_tokens=False)\n",
    "        input_indices.extend(indices)\n",
    "        \n",
    "        if token in relevant_tokens:\n",
    "            wordpiece_positions.extend(list(range(acc_len, acc_len + len(indices)))\n",
    "                                       if return_mean else [acc_len])\n",
    "        \n",
    "        acc_len += len(indices)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_output = model(torch.tensor([[CLS_ID] + input_indices + [SEP_ID]]).to(device))[0][0]\n",
    "    \n",
    "    return np.mean(model_output[wordpiece_positions].detach().cpu().numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_first = [np.vstack([get_contextual_embeddings(context, pos) for context, pos, _ in word_data])\n",
    "           for word_data in data_by_words.values()]\n",
    "X_all = [np.vstack([get_contextual_embeddings(context, pos, return_mean=True) for context, pos, _ in word_data])\n",
    "         for word_data in data_by_words.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [np.array([label for _, _, label in word_data])\n",
    "     for word_data in data_by_words.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_CLUSTERS = data.groupby('word').aggregate(lambda x: len(set(x)))['gold_sense_id'].max()\n",
    "MAX_CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringGridSearch:\n",
    "    def __init__(self, estimator, param_grid: Dict[str, list],\n",
    "                 scoring: Callable, needs_n_clusters: bool = False,\n",
    "                 dimensionality_reducer = None) -> None:\n",
    "        self.estimator = estimator\n",
    "        self.param_grid = param_grid\n",
    "        self.scoring = scoring\n",
    "        self.results_ = None\n",
    "        self.needs_n_clusters = needs_n_clusters\n",
    "        self.dimensionality_reducer = dimensionality_reducer\n",
    "        \n",
    "    def fit(self, X, y) -> None:\n",
    "        self.clear_results()\n",
    "        \n",
    "        if self.dimensionality_reducer is not None:\n",
    "            X = deepcopy(X)\n",
    "            X = [self.dimensionality_reducer.fit_transform(word_data) for word_data in X]\n",
    "        \n",
    "        max_comb = reduce(lambda x, y: x*y, [len(value) for value in self.param_grid.values()])\n",
    "        \n",
    "        for i, param_combination in tqdm(enumerate(\n",
    "            itertools.product(*[list(range(len(value))) for value in self.param_grid.values()])\n",
    "        )):\n",
    "            kwargs = {}\n",
    "            for (key, value), idx in zip(self.param_grid.items(), param_combination):\n",
    "                kwargs[key] = value[idx]\n",
    "                self.results_[key][i] = value[idx]\n",
    "            \n",
    "            score = 0\n",
    "            for word_data, word_labels in zip(X, y):\n",
    "                if self.needs_n_clusters:\n",
    "                    self.find_optimal_n_clusters(word_data, kwargs)\n",
    "                estimator = self.estimator(**kwargs)\n",
    "                \n",
    "                preds = estimator.fit_predict(word_data)\n",
    "                score += self.scoring(word_labels, preds) * len(word_data)\n",
    "            \n",
    "            score /= sum(len(word_data) for word_data in X)\n",
    "            self.results_['score'][i] = score\n",
    "            if i != max_comb - 1:\n",
    "                self.results_.loc[len(self.results_), :] = [None for _ in range(len(self.param_grid) + 1)]\n",
    "            \n",
    "            del estimator\n",
    "        \n",
    "        self.results_.score = self.results_.score.astype('float')\n",
    "    \n",
    "    def find_optimal_n_clusters(self, X, kwargs) -> None:\n",
    "        best_score, best_n_clusters = -1, 0\n",
    "        \n",
    "        for n_clusters in range(2, min(MAX_CLUSTERS, len(X) - 1)):\n",
    "            kwargs['n_clusters'] = n_clusters\n",
    "            estimator = self.estimator(**kwargs)\n",
    "            preds = estimator.fit_predict(X)\n",
    "            score = silhouette_score(X, preds)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_n_clusters = n_clusters\n",
    "        \n",
    "        kwargs['n_clusters'] = best_n_clusters\n",
    "    \n",
    "    def clear_results(self) -> None:\n",
    "        self.results_ = pd.DataFrame([[None for _ in range(len(self.param_grid) + 1)]],\n",
    "                                     columns = list(self.param_grid.keys()) + ['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ClusteringGridSearch(AffinityPropagation,\n",
    "                            {\n",
    "                                'damping': [0.5, 0.55, 0.6, 0.7, 0.8, 0.9, 0.99],\n",
    "                                'max_iter': [50, 100, 200]\n",
    "                            },\n",
    "                            adjusted_rand_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:52,  2.48s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "damping          0.6\n",
       "max_iter          50\n",
       "score       0.227508\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_first, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:48,  2.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "damping          0.5\n",
       "max_iter         200\n",
       "score       0.230609\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_all, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AffinityPropagation + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_COMP = min(x.shape[0] for x in X_first)\n",
    "N_COMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ClusteringGridSearch(AffinityPropagation,\n",
    "                            {\n",
    "                                'damping': [0.5, 0.55, 0.6, 0.7, 0.8, 0.9, 0.99],\n",
    "                                'max_iter': [50, 100, 200]\n",
    "                            },\n",
    "                            adjusted_rand_score, dimensionality_reducer=PCA(n_components=N_COMP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:37,  1.78s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "damping          0.8\n",
       "max_iter          50\n",
       "score       0.225494\n",
       "Name: 12, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_first, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:43,  2.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "damping          0.5\n",
       "max_iter          50\n",
       "score       0.223428\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_all, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AffinityPropagation + UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ClusteringGridSearch(AffinityPropagation,\n",
    "                            {\n",
    "                                'damping': [0.5, 0.55, 0.6, 0.7, 0.8, 0.9, 0.99],\n",
    "                                'preference': [None] + list(np.arange(-5.0, -1.0, 0.25)),\n",
    "                                'max_iter': [50, 100, 200]\n",
    "                            },\n",
    "                            adjusted_rand_score, dimensionality_reducer=UMAP(n_components=N_COMP-2, metric='cosine', n_neighbors=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "357it [10:55,  1.84s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "damping            0.5\n",
       "preference       -4.25\n",
       "max_iter            50\n",
       "score         0.319283\n",
       "Name: 12, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_first, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "357it [09:09,  1.54s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "damping            0.8\n",
       "preference          -4\n",
       "max_iter            50\n",
       "score         0.307646\n",
       "Name: 219, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_all, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this clustering method, the number of clusters must be passed explicitly. We are going to infer it from the data, individually for each word, using the silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ClusteringGridSearch(AgglomerativeClustering,\n",
    "                            {\n",
    "                                'affinity': ['manhattan', 'cosine'],\n",
    "                                'linkage': ['single', 'average', 'complete']\n",
    "                            },\n",
    "                            adjusted_rand_score, needs_n_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:49,  8.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "affinity    manhattan\n",
       "linkage      complete\n",
       "score        0.202546\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_first, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:35,  5.91s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "affinity      cosine\n",
       "linkage     complete\n",
       "score       0.195608\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_all, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ClusteringGridSearch(AgglomerativeClustering,\n",
    "                            {\n",
    "                                'affinity': ['manhattan', 'cosine'],\n",
    "                                'linkage': ['single', 'average', 'complete']\n",
    "                            },\n",
    "                            adjusted_rand_score, needs_n_clusters=True,\n",
    "                            dimensionality_reducer=PCA(n_components=N_COMP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:21,  3.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "affinity      cosine\n",
       "linkage     complete\n",
       "score       0.215005\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_first, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:18,  3.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "affinity      cosine\n",
       "linkage      average\n",
       "score       0.214023\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_all, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering + UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ClusteringGridSearch(AgglomerativeClustering,\n",
    "                            {\n",
    "                                'affinity': ['manhattan', 'cosine'],\n",
    "                                'linkage': ['single', 'average', 'complete']\n",
    "                            },\n",
    "                            adjusted_rand_score, needs_n_clusters=True,\n",
    "                            dimensionality_reducer=UMAP(n_components=N_COMP-2, metric='cosine', n_neighbors=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:12,  2.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "affinity    manhattan\n",
       "linkage       average\n",
       "score        0.260198\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_first, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:12,  2.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "affinity    manhattan\n",
       "linkage       average\n",
       "score        0.261971\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_all, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ClusteringGridSearch(Birch,\n",
    "                            {\n",
    "                                'threshold': [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0, 5.0, 10.0],\n",
    "                                'branching_factor': [2, 3, 4, 5, 10, 25, 50, 100]\n",
    "                            },\n",
    "                            adjusted_rand_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [01:47,  1.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "threshold                  5\n",
       "branching_factor           2\n",
       "score               0.210423\n",
       "Name: 56, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_first, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [01:48,  1.51s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "threshold               0.01\n",
       "branching_factor           2\n",
       "score               0.213639\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_all, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birch + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ClusteringGridSearch(Birch,\n",
    "                            {\n",
    "                                'threshold': [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0, 5.0, 10.0],\n",
    "                                'branching_factor': [2, 3, 4, 5, 10, 25, 50, 100]\n",
    "                            },\n",
    "                            adjusted_rand_score, dimensionality_reducer=PCA(n_components=N_COMP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [00:37,  1.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "threshold                  1\n",
       "branching_factor           4\n",
       "score               0.220705\n",
       "Name: 50, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_first, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [00:38,  1.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "threshold                  1\n",
       "branching_factor           4\n",
       "score               0.216445\n",
       "Name: 50, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_all, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birch + UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ClusteringGridSearch(Birch,\n",
    "                            {\n",
    "                                'threshold': [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0, 5.0, 10.0],\n",
    "                                'branching_factor': [2, 3, 4, 5, 10, 25, 50, 100]\n",
    "                            },\n",
    "                            adjusted_rand_score,\n",
    "                            dimensionality_reducer=UMAP(n_components=N_COMP-2, metric='cosine', n_neighbors=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [00:29,  2.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "threshold               0.75\n",
       "branching_factor          10\n",
       "score               0.267725\n",
       "Name: 44, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_first, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [00:28,  2.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "threshold               0.75\n",
       "branching_factor          10\n",
       "score               0.255086\n",
       "Name: 44, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_all, y)\n",
    "grid.results_.loc[grid.results_.score.idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best clustering algorithm turned out to be Affinity Propagation over UMAP-reduced contextual embeddings with the following hyperparameters:\n",
    "- UMAP: n_components = 5 (or less, see the code below), metric = cosine, n_neighbors = 10, the rest of the parameters: default values\n",
    "- AffinityPropagation: damping = 0.5, preference = -4.25, max_iter = 50\n",
    "\n",
    "Furthermore, it is slightly beneficial to use just the first wordpiece of a token as its contextual representation. One could argue that suffixes do not carry a lot of information relevant for WSI.\n",
    "\n",
    "Let's run this pipeline for the test data and write down the result to be evaluated with the provided Python script.\n",
    "\n",
    "P. S. The additional dataset, weirdly, uses different indexing, so we need to correct that by adding 2 to the end of every span."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>word</th>\n",
       "      <th>gold_sense_id</th>\n",
       "      <th>predict_sense_id</th>\n",
       "      <th>positions</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2074</td>\n",
       "      <td>давление</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(0, 9)]</td>\n",
       "      <td>Давление пара создается движением поршня в цил...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2075</td>\n",
       "      <td>давление</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(13, 22)]</td>\n",
       "      <td>«У тебя что, давление поднялось?» Я сказал, чт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2076</td>\n",
       "      <td>давление</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(56, 65)]</td>\n",
       "      <td>Я жалуюсь Никоновичу наконец на головокружение...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2077</td>\n",
       "      <td>давление</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(0, 9)]</td>\n",
       "      <td>Давление в котле не менялось</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2078</td>\n",
       "      <td>давление</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(25, 34)]</td>\n",
       "      <td>Он каждые два часа мерил давление и сахар в крови</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3724</td>\n",
       "      <td>5798</td>\n",
       "      <td>зуд</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(43, 47)]</td>\n",
       "      <td>Многих американцев одолевает романтический зуд...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3725</td>\n",
       "      <td>5799</td>\n",
       "      <td>зуд</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(23, 27)]</td>\n",
       "      <td>Если на нее не находил зуд рассказывания истор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3726</td>\n",
       "      <td>5800</td>\n",
       "      <td>зуд</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(27, 33)]</td>\n",
       "      <td>С раздражающей завистью, с зудом неудовлетворе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3727</td>\n",
       "      <td>5801</td>\n",
       "      <td>зуд</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(12, 16)]</td>\n",
       "      <td>Нестерпимый зуд любопытства</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3728</td>\n",
       "      <td>5802</td>\n",
       "      <td>зуд</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(17, 21)]</td>\n",
       "      <td>В ноге был такой зуд, что Матвееву хотелось сн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3685 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      context_id      word gold_sense_id  predict_sense_id   positions  \\\n",
       "0           2074  давление             1               NaN    [(0, 9)]   \n",
       "1           2075  давление           2.2               NaN  [(13, 22)]   \n",
       "2           2076  давление           2.2               NaN  [(56, 65)]   \n",
       "3           2077  давление           2.1               NaN    [(0, 9)]   \n",
       "4           2078  давление           2.2               NaN  [(25, 34)]   \n",
       "...          ...       ...           ...               ...         ...   \n",
       "3724        5798       зуд             2               NaN  [(43, 47)]   \n",
       "3725        5799       зуд             2               NaN  [(23, 27)]   \n",
       "3726        5800       зуд             2               NaN  [(27, 33)]   \n",
       "3727        5801       зуд             2               NaN  [(12, 16)]   \n",
       "3728        5802       зуд             1               NaN  [(17, 21)]   \n",
       "\n",
       "                                                context  \n",
       "0     Давление пара создается движением поршня в цил...  \n",
       "1     «У тебя что, давление поднялось?» Я сказал, чт...  \n",
       "2     Я жалуюсь Никоновичу наконец на головокружение...  \n",
       "3                          Давление в котле не менялось  \n",
       "4     Он каждые два часа мерил давление и сахар в крови  \n",
       "...                                                 ...  \n",
       "3724  Многих американцев одолевает романтический зуд...  \n",
       "3725  Если на нее не находил зуд рассказывания истор...  \n",
       "3726  С раздражающей завистью, с зудом неудовлетворе...  \n",
       "3727                        Нестерпимый зуд любопытства  \n",
       "3728  В ноге был такой зуд, что Матвееву хотелось сн...  \n",
       "\n",
       "[3685 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/nsykhr/russe-wsi-kit/master/data/main/active-dict/test-solution.csv', sep='\\t')\n",
    "data.dropna(subset=['positions'], inplace=True) # let's drop the rows where the relevant token is not present in the context\n",
    "data.positions = data.positions.apply(lambda x: [tuple(map(int, pos.split('-'))) for pos in x.split(',')])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_words = {key: [] for key in data.word.unique()}\n",
    "for i, row in data.iterrows():\n",
    "    data_by_words[row.word].append((row.context, row.positions, row.gold_sense_id, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [np.vstack([get_contextual_embeddings(context, pos) for context, pos, _, _ in word_data])\n",
    "     for word_data in data_by_words.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [07:35,  2.71s/it]\n"
     ]
    }
   ],
   "source": [
    "aff = AffinityPropagation(damping=0.5, preference=-4.25, max_iter=50)\n",
    "\n",
    "for word, word_data in tqdm(zip(data_by_words, X)):\n",
    "    n_components = min(5, len(data_by_words[word]) - 2)\n",
    "    umap = UMAP(n_components=n_components, metric='cosine', n_neighbors=10)\n",
    "    \n",
    "    preds = aff.fit_predict(umap.fit_transform(word_data))\n",
    "    for pred, row in zip(preds, data_by_words[word]):\n",
    "        data.predict_sense_id.loc[row[-1]] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>word</th>\n",
       "      <th>gold_sense_id</th>\n",
       "      <th>predict_sense_id</th>\n",
       "      <th>positions</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2074</td>\n",
       "      <td>давление</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[(0, 9)]</td>\n",
       "      <td>Давление пара создается движением поршня в цил...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2075</td>\n",
       "      <td>давление</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(13, 22)]</td>\n",
       "      <td>«У тебя что, давление поднялось?» Я сказал, чт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2076</td>\n",
       "      <td>давление</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(56, 65)]</td>\n",
       "      <td>Я жалуюсь Никоновичу наконец на головокружение...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2077</td>\n",
       "      <td>давление</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(0, 9)]</td>\n",
       "      <td>Давление в котле не менялось</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2078</td>\n",
       "      <td>давление</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(25, 34)]</td>\n",
       "      <td>Он каждые два часа мерил давление и сахар в крови</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3724</td>\n",
       "      <td>5798</td>\n",
       "      <td>зуд</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(43, 47)]</td>\n",
       "      <td>Многих американцев одолевает романтический зуд...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3725</td>\n",
       "      <td>5799</td>\n",
       "      <td>зуд</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(23, 27)]</td>\n",
       "      <td>Если на нее не находил зуд рассказывания истор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3726</td>\n",
       "      <td>5800</td>\n",
       "      <td>зуд</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(27, 33)]</td>\n",
       "      <td>С раздражающей завистью, с зудом неудовлетворе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3727</td>\n",
       "      <td>5801</td>\n",
       "      <td>зуд</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(12, 16)]</td>\n",
       "      <td>Нестерпимый зуд любопытства</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3728</td>\n",
       "      <td>5802</td>\n",
       "      <td>зуд</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[(17, 21)]</td>\n",
       "      <td>В ноге был такой зуд, что Матвееву хотелось сн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3685 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      context_id      word gold_sense_id  predict_sense_id   positions  \\\n",
       "0           2074  давление             1               2.0    [(0, 9)]   \n",
       "1           2075  давление           2.2               0.0  [(13, 22)]   \n",
       "2           2076  давление           2.2               0.0  [(56, 65)]   \n",
       "3           2077  давление           2.1               0.0    [(0, 9)]   \n",
       "4           2078  давление           2.2               0.0  [(25, 34)]   \n",
       "...          ...       ...           ...               ...         ...   \n",
       "3724        5798       зуд             2               1.0  [(43, 47)]   \n",
       "3725        5799       зуд             2               1.0  [(23, 27)]   \n",
       "3726        5800       зуд             2               0.0  [(27, 33)]   \n",
       "3727        5801       зуд             2               1.0  [(12, 16)]   \n",
       "3728        5802       зуд             1               0.0  [(17, 21)]   \n",
       "\n",
       "                                                context  \n",
       "0     Давление пара создается движением поршня в цил...  \n",
       "1     «У тебя что, давление поднялось?» Я сказал, чт...  \n",
       "2     Я жалуюсь Никоновичу наконец на головокружение...  \n",
       "3                          Давление в котле не менялось  \n",
       "4     Он каждые два часа мерил давление и сахар в крови  \n",
       "...                                                 ...  \n",
       "3724  Многих американцев одолевает романтический зуд...  \n",
       "3725  Если на нее не находил зуд рассказывания истор...  \n",
       "3726  С раздражающей завистью, с зудом неудовлетворе...  \n",
       "3727                        Нестерпимый зуд любопытства  \n",
       "3728  В ноге был такой зуд, что Матвееву хотелось сн...  \n",
       "\n",
       "[3685 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/main/active-dict/result_conv_bert_aff.csv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that I ran the baseline algorithm (Adagram) on the test data to get its predictions and the evaluation script three times to compare the metrics. Adagram achieves __0.161189__ ARI, while my algorithm achieves __0.273346__ ARI. On the training data, Adagram achieves only __0.159930__ ARI, while my algorithm achieves __0.319283__ ARI. Thus, I was able to very significantly improve over the baseline and achieve a very competitive result. If you choose to re-run the prediction code, keep in mind that UMAP may yield different results depending on its random initialization. Voting over several random seeds could both improve and stabilize the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>word</th>\n",
       "      <th>gold_sense_id</th>\n",
       "      <th>predict_sense_id</th>\n",
       "      <th>positions</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>альбом</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(88, 96)]</td>\n",
       "      <td>достаточно лишь колесиком мышки крутить вниз. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>альбом</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(85, 93)]</td>\n",
       "      <td>выступал в составе команды с таким названием, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>альбом</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(81, 89)]</td>\n",
       "      <td>. Работает так себе, поскольку функция заточен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>альбом</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(84, 91)]</td>\n",
       "      <td>одержала победу в двух из пяти номинаций: 'Луч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>альбом</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(83, 90)]</td>\n",
       "      <td>встречи с Божественным. Вы испытаете ни с чем ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3666</td>\n",
       "      <td>3667</td>\n",
       "      <td>группа</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(102, 109)]</td>\n",
       "      <td>напротив, цветет пуще прежнего. География расш...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3667</td>\n",
       "      <td>3668</td>\n",
       "      <td>группа</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(93, 100)]</td>\n",
       "      <td>синтетической работе, терпение и упорство, жел...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3668</td>\n",
       "      <td>3669</td>\n",
       "      <td>группа</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(20, 27)]</td>\n",
       "      <td>Маркетинг процедуры.Группа компаний Кивеннапа ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3669</td>\n",
       "      <td>3670</td>\n",
       "      <td>группа</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(100, 107)]</td>\n",
       "      <td>International» признались миллионам слушателей...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3670</td>\n",
       "      <td>3671</td>\n",
       "      <td>группа</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(103, 110)]</td>\n",
       "      <td>Абрамовым, Гарик Мартиросян с женой Жанной, Ти...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3671 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      context_id    word  gold_sense_id  predict_sense_id     positions  \\\n",
       "0              1  альбом              2               NaN    [(88, 96)]   \n",
       "1              2  альбом              3               NaN    [(85, 93)]   \n",
       "2              3  альбом              2               NaN    [(81, 89)]   \n",
       "3              4  альбом              3               NaN    [(84, 91)]   \n",
       "4              5  альбом              3               NaN    [(83, 90)]   \n",
       "...          ...     ...            ...               ...           ...   \n",
       "3666        3667  группа              4               NaN  [(102, 109)]   \n",
       "3667        3668  группа              4               NaN   [(93, 100)]   \n",
       "3668        3669  группа              4               NaN    [(20, 27)]   \n",
       "3669        3670  группа              4               NaN  [(100, 107)]   \n",
       "3670        3671  группа              4               NaN  [(103, 110)]   \n",
       "\n",
       "                                                context  \n",
       "0     достаточно лишь колесиком мышки крутить вниз. ...  \n",
       "1     выступал в составе команды с таким названием, ...  \n",
       "2     . Работает так себе, поскольку функция заточен...  \n",
       "3     одержала победу в двух из пяти номинаций: 'Луч...  \n",
       "4     встречи с Божественным. Вы испытаете ни с чем ...  \n",
       "...                                                 ...  \n",
       "3666  напротив, цветет пуще прежнего. География расш...  \n",
       "3667  синтетической работе, терпение и упорство, жел...  \n",
       "3668  Маркетинг процедуры.Группа компаний Кивеннапа ...  \n",
       "3669  International» признались миллионам слушателей...  \n",
       "3670  Абрамовым, Гарик Мартиросян с женой Жанной, Ти...  \n",
       "\n",
       "[3671 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/nsykhr/russe-wsi-kit/master/data/additional/active-rutenten/train.csv', sep='\\t')\n",
    "data.dropna(subset=['positions'], inplace=True) # let's drop the rows where the relevant token is not present in the context\n",
    "data.positions = data.positions.apply(lambda x: [tuple(map(int, pos.split('-'))) for pos in x.split(',')])\n",
    "data.positions = data.positions.apply(lambda x: [(a, b+2) for a, b in x])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several sentences in the dataset that cannot be tokenized correctly. I have to resort to correcting them manually (add a whitespace or two) because I do not have the time nor the resources to use/train a neural tokenizer or create complex tokenization rules for such sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.context.loc[494] = '15, 000 на всех членов семьи.Вот тогда и законы будут человечными Анатомия и физиология человека'\n",
    "data.positions.loc[494] = [(66, 75)]\n",
    "\n",
    "data.context.loc[1202] = 'выше чем 1 метр или до 12 лет-8 евро, дети ниже чем 1 метр –вход бесплатный Билеты: взрослые-16 евро, дети выше чем 1 метр или старше 10 лет-12 евро, дети до 10 лет'\n",
    "data.positions.loc[1202] = [(76, 83)]\n",
    "\n",
    "data.context.loc[1381] = 'крепление Крепление на стену по стандарту VESA 100мм Блок питания внешний'\n",
    "data.positions.loc[1381] = [(53, 58)]\n",
    "\n",
    "data.context.loc[1398] = 'Пористые заполнители Блоки оконные'\n",
    "data.positions.loc[1398] = [(21, 27)]\n",
    "\n",
    "data.context.loc[1432] = 'СКАТ БЛОКИ ПИТАНИЯ БПУ-24-0,5; БПУ-24-0,7; БПУ-12 -1,5; БПС -12 -0,7; БП-TV1; БП-TV3 БЛОК ПИТАНИЯ СЕТЕВОЙ БПС СИСТЕМА ДИСТАНЦИОННОГО... БПС -12 . Блок питания с симисторами'\n",
    "data.positions.loc[1432] = [(85, 90)]\n",
    "\n",
    "data.context.loc[1514] = 'Библиографические ресурсы и каталоги Блок библиографических ресурсов глобальных сетей обширен и разнообразен. Его главной'\n",
    "data.positions.loc[1514] = [(37, 42)]\n",
    "\n",
    "data.context.loc[2019] = 'Выпускаемая продукция Вешалка детская'\n",
    "data.positions.loc[2019] = [(22, 30)]\n",
    "\n",
    "data.context.loc[2566] = 'Электропроводка для подключения светодиодных знаков в задней части прицепа вилка/розетка) для подключения электрооборудования прицепа к электросети автомобиля'\n",
    "data.positions.loc[2566] = [(75, 81)]\n",
    "\n",
    "data.context.loc[2811] = 'Волги только левым расположением запасного колеса. Оно так же прикручено винтом. горизонтальным торсионам и удерживалась ими в открытом положении. Причем оригинальной'\n",
    "data.positions.loc[2811] = [(73, 80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_words = {key: [] for key in data.word.unique()}\n",
    "for i, row in data.iterrows():\n",
    "    data_by_words[row.word].append((row.context, row.positions, row.gold_sense_id, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [np.vstack([get_contextual_embeddings(context, pos) for context, pos, _, _ in word_data])\n",
    "     for word_data in data_by_words.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [01:04,  3.23s/it]\n"
     ]
    }
   ],
   "source": [
    "aff = AffinityPropagation(damping=0.5, preference=-4.25, max_iter=50)\n",
    "\n",
    "for word, word_data in tqdm(zip(data_by_words, X)):\n",
    "    n_components = min(5, len(data_by_words[word]) - 2)\n",
    "    umap = UMAP(n_components=n_components, metric='cosine', n_neighbors=10)\n",
    "    \n",
    "    preds = aff.fit_predict(umap.fit_transform(word_data))\n",
    "    for pred, row in zip(preds, data_by_words[word]):\n",
    "        data.predict_sense_id.loc[row[-1]] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>word</th>\n",
       "      <th>gold_sense_id</th>\n",
       "      <th>predict_sense_id</th>\n",
       "      <th>positions</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>альбом</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(88, 96)]</td>\n",
       "      <td>достаточно лишь колесиком мышки крутить вниз. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>альбом</td>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[(85, 93)]</td>\n",
       "      <td>выступал в составе команды с таким названием, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>альбом</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[(81, 89)]</td>\n",
       "      <td>. Работает так себе, поскольку функция заточен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>альбом</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[(84, 91)]</td>\n",
       "      <td>одержала победу в двух из пяти номинаций: 'Луч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>альбом</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[(83, 90)]</td>\n",
       "      <td>встречи с Божественным. Вы испытаете ни с чем ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3666</td>\n",
       "      <td>3667</td>\n",
       "      <td>группа</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(102, 109)]</td>\n",
       "      <td>напротив, цветет пуще прежнего. География расш...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3667</td>\n",
       "      <td>3668</td>\n",
       "      <td>группа</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[(93, 100)]</td>\n",
       "      <td>синтетической работе, терпение и упорство, жел...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3668</td>\n",
       "      <td>3669</td>\n",
       "      <td>группа</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[(20, 27)]</td>\n",
       "      <td>Маркетинг процедуры.Группа компаний Кивеннапа ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3669</td>\n",
       "      <td>3670</td>\n",
       "      <td>группа</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(100, 107)]</td>\n",
       "      <td>International» признались миллионам слушателей...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3670</td>\n",
       "      <td>3671</td>\n",
       "      <td>группа</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(103, 110)]</td>\n",
       "      <td>Абрамовым, Гарик Мартиросян с женой Жанной, Ти...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3671 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      context_id    word  gold_sense_id  predict_sense_id     positions  \\\n",
       "0              1  альбом              2               3.0    [(88, 96)]   \n",
       "1              2  альбом              3              16.0    [(85, 93)]   \n",
       "2              3  альбом              2               3.0    [(81, 89)]   \n",
       "3              4  альбом              3               2.0    [(84, 91)]   \n",
       "4              5  альбом              3              10.0    [(83, 90)]   \n",
       "...          ...     ...            ...               ...           ...   \n",
       "3666        3667  группа              4               1.0  [(102, 109)]   \n",
       "3667        3668  группа              4               8.0   [(93, 100)]   \n",
       "3668        3669  группа              4               8.0    [(20, 27)]   \n",
       "3669        3670  группа              4               1.0  [(100, 107)]   \n",
       "3670        3671  группа              4               1.0  [(103, 110)]   \n",
       "\n",
       "                                                context  \n",
       "0     достаточно лишь колесиком мышки крутить вниз. ...  \n",
       "1     выступал в составе команды с таким названием, ...  \n",
       "2     . Работает так себе, поскольку функция заточен...  \n",
       "3     одержала победу в двух из пяти номинаций: 'Луч...  \n",
       "4     встречи с Божественным. Вы испытаете ни с чем ...  \n",
       "...                                                 ...  \n",
       "3666  напротив, цветет пуще прежнего. География расш...  \n",
       "3667  синтетической работе, терпение и упорство, жел...  \n",
       "3668  Маркетинг процедуры.Группа компаний Кивеннапа ...  \n",
       "3669  International» признались миллионам слушателей...  \n",
       "3670  Абрамовым, Гарик Мартиросян с женой Жанной, Ти...  \n",
       "\n",
       "[3671 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/additional/active-rutenten/result_conv_bert_aff.csv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this dataset, my algorithm demonstrates a measly __0.057292__ ARI. Clearly, the hyperparameters of the model need to be tuned separately for this data since the current algorithm predicts much more granular senses than there are in the labels (illustration below). Since this is impossible, I will try another approach to tackle this data (see the other notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_sense_id</th>\n",
       "      <th>predict_sense_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>альбом</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>анатомия</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>базар</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>балет</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>беда</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>бездна</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>билет</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>блок</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>блоха</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>брак</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>бритва</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>будущее</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>вешалка</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>вилка</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>винт</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>галерея</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>горбуша</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>горшок</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>гроза</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>группа</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gold_sense_id  predict_sense_id\n",
       "word                                     \n",
       "альбом                3                24\n",
       "анатомия              3                 9\n",
       "базар                 3                 8\n",
       "балет                 4                10\n",
       "беда                  2                11\n",
       "бездна                4                 7\n",
       "билет                 4                26\n",
       "блок                  8                14\n",
       "блоха                 2                 8\n",
       "брак                  2                10\n",
       "бритва                2                 7\n",
       "будущее               2                 8\n",
       "вешалка               5                22\n",
       "вилка                 5                20\n",
       "винт                  5                20\n",
       "галерея               3                 4\n",
       "горбуша               2                 7\n",
       "горшок                3                19\n",
       "гроза                 4                 8\n",
       "группа                5                 9"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['word', 'gold_sense_id', 'predict_sense_id']].groupby(by=['word']).\\\n",
    "    aggregate(lambda x: len(set(x))).applymap(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
